{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Donación\n",
    "\n",
    "Este es el último proyecto de aprendizaje supervisado. En este cuaderno, parte del código ya está implementado y tu tarea es implementar funcionalidad necesaria para completarlo. Adicionalmente, habrán preguntas que deberás responder relacionadas a tus implementaciones. Lee el contenido con cuidado.\n",
    "\n",
    "En este proyecto, utilizarás diferentes algoritmos de aprendizaje supervisado para modelar los ingresos utilizando data de un censo de Estados Unidos de 1994. Después, tú decidirás los mejores candidatos de resultados preliminares y luego optimizarás del algoritmo. El objetivo en esta implementación es construir un modelo que prediga cuando un individuo gana más de $50,000. Entender los ingresos de individuos nos permitirá determinar qué número decir cuando pedimos donaciones. \n",
    "\n",
    "El dataset que utilizaremos viene del UCI Machine Learning Repository. Este dataset ha sido donado después de un artículo publicado.\n",
    "\n",
    "\n",
    "## Exploración\n",
    "Corre la siguiente celda para cargar las librerías necesarias de Python y cargar la información. Mira que la última columna, income, es nuestro label objetivo. El resto son features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías necesarias para el proyecto\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from IPython.display import display\n",
    "\n",
    "# Importamos visualizaciones ya implementadas\n",
    "import visuals as vs\n",
    "\n",
    "# Para mostrar gráficas en cuadernos\n",
    "%matplotlib inline\n",
    "\n",
    "# Cargamos info del csv\n",
    "data = pd.read_csv(\"data/census.csv\")\n",
    "\n",
    "# Mostramos primer resultado\n",
    "display(data.head(n=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniciaremos investigando el dataset para determinar cuántos individuos entran en cada grupo de salarios, y nos dirá el porcentaje de individuos haciendo más de \\$50,000. En la siguiente celda necesitas programar lo siguiente:\n",
    "\n",
    "* `n_records`: el número total de records.\n",
    "* `n_greater_50k`: el número de individuos que ganan más de $50,000 al año.\n",
    "* `n_at_most_50k`: el número de individuos que hacen como mucho \\$50,000 al año.\n",
    "* `greater_percent`: el porcentaje de individuos ganando más de \\$50,000 al año."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_records = # TODO\n",
    "\n",
    "n_greater_50k = # TODO\n",
    "\n",
    "n_at_most_50k = # TODO\n",
    "\n",
    "greater_percent = # TODO\n",
    "\n",
    "# Print the results\n",
    "print(\"Total number of records: {}\".format(n_records))\n",
    "print(\"Individuals making more than $50,000: {}\".format(n_greater_50k))\n",
    "print(\"Individuals making at most $50,000: {}\".format(n_at_most_50k))\n",
    "print(\"Percentage of individuals making more than $50,000: {}%\".format(greater_percent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploración de features\n",
    "\n",
    "* age: continuo.\n",
    "* workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    "* educatio: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
    "* education-num: continuo.\n",
    "* marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
    "* occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
    "* relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
    "* race: Black, White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other.\n",
    "* sex: Female, Male.\n",
    "* capital-gain: continuo.\n",
    "* capital-loss: continuo.\n",
    "* hours-per-week: continuo.\n",
    "* native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando la información\n",
    "\n",
    "Antes de poder utilizar la información como entrada de algoritmos de ML, es necesario limpiar la información, darle un formato, y restructurarla (preprocesamiento). En este caso, afortunadamente, no hay entradas que falten o inválidas con las que tengamos que lidiar. Aún así, hay ciertas cualidades que debemos ajustar que ayudarán mucho a los algoritmos.\n",
    "\n",
    "\n",
    "### Transformando features continuos sesgados\n",
    "En un dataset es común ver features cuyos valores siempre suelen estar cerca de un número individual, pero que también tienen resultados mucho más largos o mucho más pequeños. Los algoritmos son afectados a esos tipos de distribuciones y suelen desempeñarse peor si el rango no está normalizado. Los dos features con los que nos pasa esto son `capital-gain` y `capital-loss`. \n",
    "\n",
    "Haremos un histrograma de estos dos features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target label\n",
    "income_raw = data['income']\n",
    "features_raw = data.drop('income', axis = 1)\n",
    "\n",
    "# Visualize skewed continuous features of original data\n",
    "vs.distribution(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para features con distribuciones tan sesgadas como `capital-gain` y `capital-loss`, es una práctica común aplicar transformación logarítmica para que los valores muy largos o muy pequeños no afecten negativamente el desempeño del algoritmo. Utilizar esta transformación reduce el rango de los valores causado por los outliers. Hay que tener cuidado porque el logaritmo de 0 no está definido, por lo que debemos transladar los valores a una pequeña cantidad sobre 0 para poderles aplicar la transformación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-transform the skewed features\n",
    "skewed = ['capital-gain', 'capital-loss']\n",
    "features_log_transformed = pd.DataFrame(data = features_raw)\n",
    "features_log_transformed[skewed] = features_raw[skewed].apply(lambda x: np.log(x + 1))\n",
    "\n",
    "# Visualize the new log distributions\n",
    "vs.distribution(features_log_transformed, transformed = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizando features numéricos\n",
    "\n",
    "Además de transformar los features sesgados, es buena práctica escalar los features numéricos. Aplicar una escala no cambia la forma de la distribución de los features; normalizar asegura que cada feature sea tratado de la misma manera por un algoritmo de aprendizaje. Recuerda que una vez que apliquemos la transformación, las visualizaciones de la información ya no tendrán el mismo significado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sklearn.preprocessing.StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize a scaler, then apply it to the features\n",
    "scaler = MinMaxScaler() # default=(0, 1)\n",
    "numerical = ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "\n",
    "features_log_minmax_transform = pd.DataFrame(data = features_log_transformed)\n",
    "features_log_minmax_transform[numerical] = scaler.fit_transform(features_log_transformed[numerical])\n",
    "\n",
    "# Show an example of a record with scaling applied\n",
    "display(features_log_minmax_transform.head(n = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de Data\n",
    "\n",
    "De la tabla de arriba, podemos ver que muchos features son no numéricos (categóricos). Típicamente, los algoritmos de aprendizaje esperan entradas numéricas, por lo que convertiremos los otros features. Una manera popular de convertir variables categóricas es utilizando one-hot encoding, como hemos visto en redes neuronales también. \n",
    "\n",
    "Con one-hot encoding, creamos una variable \"dummy\" para cada posible categoría de los features categóricos. Por ejemplo, digamos que tenemos unFeature que tiene tres entradas posibles: A, B o C. Convertiremos esto a tres features: unFeatureA, unFeatureB y unFeatureC.\n",
    "\n",
    "|            | Feature|\n",
    "| ------------- |--------|\n",
    "| 0      | B |  |\n",
    "| 1      | C    |\n",
    "| 2 | A         |\n",
    "\n",
    "Se convierte en \n",
    "\n",
    "|            | A| B | C\n",
    "| -------- |--------|--------|--------|\n",
    "| 0      | 0 | 1 | 0 |\n",
    "| 1      | 0 |0 |1    |\n",
    "| 2      | 1 | 0| 0|\n",
    "\n",
    "Adicionalmente, también tendremos que convertir el label por ser no numérico. En este caso, `income` puede ser \">50k\" o \"<=50k\". Como sólo hay dos posibles valores, vamos a saltarnos el paso de hacer one-hot encoding y vamos a convertirlo a 0 y 1, respectivamente. \n",
    "\n",
    "En la siguiente celda implementaremos lo siguiente:\n",
    "* Usa `pandas.get_dummies()` para aplicar one-hot encoding en `features_log_minmax_transform`.\n",
    "* Convierte la etiqueta objetivo `income_raw` a entradas numéricas.\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: One-hot encode the 'features_log_minmax_transform' data using pandas.get_dummies()\n",
    "features_final = # TODO\n",
    "\n",
    "# TODO: Encode the 'income_raw' data to numerical values\n",
    "income = # TODO\n",
    "\n",
    "# Print the number of features after one-hot encoding\n",
    "encoded = list(features_final.columns)\n",
    "print(\"{} total features after one-hot encoding.\".format(len(encoded)))\n",
    "\n",
    "print(encoded)\n",
    "print(income[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barajar y separar Data\n",
    "Ya hemos convertidos todas las variables categóricas a features numéricos. Todos los features, adicionalmente, han sido normalizados. Como siempre, vamos a separar en training y testing (80% y 20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Split the 'features' and 'income' data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_final, \n",
    "                                                    income, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 0)\n",
    "\n",
    "# Show the results of the split\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluando Desempeño del Modelo\n",
    "En esta sección vamos a experimentar con cuatro algoritmos diferentes y determinaremos cuál modela mejor la información. Tres de estos son algoritmos supervisados que tú decidirás, y el cuarto será un predictor naive. \n",
    "\n",
    "### Métricas y Naive Predictor\n",
    "Sabemos que es más probable que los individuos que ganan más de \\$50,000 donen a caridad. Por lo tanto, estamos particularmente interesados en predecir quiénes hacen más de \\$50,000 con exactitud (accuracy). Por lo tanto, parece más apropiado utilizar accuracy como métrica para evaluar el desempeño de cada modelo. Adicionalmente, identificar a alguien que hace menos de \\$50,000 como alguien que lo hace puede afectar negativamente el problema que queremos solucionar. Por lo tanto, nos importa más la precisión que el recall. Por lo tanto, utilizaremos F-beta, la métrica que considera tanto precision como recall.\n",
    "\n",
    "![f-beta](https://render.githubusercontent.com/render/math?math=F_%7B%5Cbeta%7D%20%3D%20%281%20%2B%20%5Cbeta%5E2%29%20%5Ccdot%20%5Cfrac%7Bprecision%20%5Ccdot%20recall%7D%7B%5Cleft%28%20%5Cbeta%5E2%20%5Ccdot%20precision%20%5Cright%29%20%2B%20recall%7D&mode=display \"f-beta\")\n",
    "\n",
    "Cuando $\\beta = 0.5$, se da más enfasis en la precisión. Esto se llama F$_{0.5}$ score.\n",
    "\n",
    "Mirando la distribución de las clases, es claro que la mayoría de los individuos hacen menos de \\$50,000. Esto puede afectar la exactitud: podríamos decir que nadie hace más de \\$50,000, y, en general, el modelo estaría correcto. Sería un modelo exacto. Obviamente, esta es una decisión ingenua. Es importante iniciar estableciendo una predicción ingenua para poder establecer una base a partir de la cuál el modelo lo hará bien. \n",
    "\n",
    "**Recap**\n",
    "\n",
    "**Accuracy**: mide qué tanto un clasificador hace predicciones correctas. Es la proporción entre predicciones correctas y el total de predicciones.\n",
    "\n",
    "**Precision**: mide, de la proporción de mensajes clasificados como spam, cuántos en verdad lo eran. Es la porporción de positivos verdaderos a todos los positivos (todos los mensajes clasificados como spam):\n",
    "\n",
    "```[True Positives/(True Positives + False Positives)]```\n",
    "\n",
    "**Recall (sensitividad)**: mide, de la porporción de mensajes que eran spam, cuántos fueron clasificados como spam. Es la proporción de positivos verdaderos a todos los mensajes que realmente eran spam:\n",
    "\n",
    "```[True Positives/(True Positives + False Negatives)]```\n",
    "\n",
    "Para problemas de clasificación sesgados en sus distribuciones, como en este caso, la exactitud (accuracy) no es una buena métrica por lo que hemos discutido. Precisión y recall nos vienen bien. Combinamos ambas métricas en F1, que, como discutimos, el el promedio harmónica de ambos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 1 - Desempeño de Predictor Ingenuo\n",
    "\n",
    "Si elegimos un modelo que siempre predice que el individuo hizo más de $50,000, ¿cuál sería la exactitud y el F1-score en el dataset? Usa la siguiente celda.\n",
    "\n",
    "**Nota**: Recuerda que el objetivo de generar un predictor ingenuo simplemente es ver lo que puede lograr un modelo iniciar sin inteligencia. En el mundo real, este predictor puede ser los resultados de un modelo previo, o los resultados de un paper de investigación que estás mejorando. Si no hay manera de establecer un modelo base, el primer objetivo suele hacer crear un modelo que lo haga mejor que un modelo aleatorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recuerda que en income tenemos 0's y 1's. Si sumamos todos los valores, nos dan cuántos tienen >50K.\n",
    "TP = np.sum(income) \n",
    "\n",
    "# Los falsos positivos son los que no tienen valor de 1. Es decir, el total - TP.\n",
    "FP = income.count() - TP\n",
    "\n",
    "# No se predicen negativos en este ejemplo\n",
    "TN = 0 \n",
    "FN = 0\n",
    "\n",
    "accuracy = # TODO\n",
    "\n",
    "# No hay falsos negativos\n",
    "recall = # TODO\n",
    "\n",
    "# [True Positives/(True Positives + False Positives)]\n",
    "precision = # TODO\n",
    "\n",
    "beta = 0.5\n",
    "\n",
    "# TODO: Calculate F-score using the formula above for beta = 0.5 and correct values for precision and recall.\n",
    "fscore = \n",
    "\n",
    "# Print the results \n",
    "print(\"Naive Predictor: [Accuracy score: {:.4f}, F-score: {:.4f}]\".format(accuracy, fscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de Aprendizaje Supervisado\n",
    "\n",
    "Estos son algunos de los modelos que hemos vistos y tenemos en scikit-learn:\n",
    "* Gaussian Naive Bayes (GaussianNB)\n",
    "* Decision Trees\n",
    "* K-Nearest Neighbors (KKNeighbors)\n",
    "* Stochastic Gradient Descent Classifier (SGDC)\n",
    "* Support Vector Machines (SVM)\n",
    "* Logistic Regression\n",
    "\n",
    "## Pregunta 2 - Aplicando el modelo\n",
    "Lista 3 modelos de aprendizaje supervisado que utilizarás para probar. Para cada modelo:\n",
    "* Describe una aplicación del mundo real donde ese tipo de modelo se puede aplicr\n",
    "* Cuáles son las fortalezas. ¿Dónde se desempeña bien?\n",
    "* Cuáles son las debilidades. ¿Dónde no desempeña bien?\n",
    "* ¿Por qué este modelo es un buen candidato para este problema?\n",
    "\n",
    "** Respuesta** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "En la siguiente celda, vas a tener que:\n",
    "* Importar `fbeta_score` y `accuracy_score` de `sklearn.metrics`.\n",
    "* Entrenar el modelo con la data de entrenamiento y registrar el tiempo\n",
    "* Hacer predicciones en el testing set y, adiconalmente, en los primeros 300 puntos de entrenamiento `X_train[:300]`.\n",
    "* Registrar el tiempo total de predicción.\n",
    "* Calcular el accuracy en training y testing.\n",
    "* Calcular el F-score para ambos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import two metrics from sklearn - fbeta_score and accuracy_score\n",
    "\n",
    "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test): \n",
    "    '''\n",
    "    inputs:\n",
    "       - learner: the learning algorithm to be trained and predicted on\n",
    "       - sample_size: the size of samples (number) to be drawn from training set\n",
    "       - X_train: features training set\n",
    "       - y_train: income training set\n",
    "       - X_test: features testing set\n",
    "       - y_test: income testing set\n",
    "    '''\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # TODO: Fit the learner to the training data using slicing with 'sample_size' using .fit(training_features[:], training_labels[:])\n",
    "    start = time() # Get start time\n",
    "    learner = \n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # TODO: Calculate the training time\n",
    "    results['train_time'] = \n",
    "        \n",
    "    # TODO: Get the predictions on the test set(X_test),\n",
    "    #       then get predictions on the first 300 training samples(X_train) using .predict()\n",
    "    start = time() # Get start time\n",
    "    predictions_test =\n",
    "    predictions_train =\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # TODO: Calculate the total prediction time\n",
    "    results['pred_time'] =\n",
    "            \n",
    "    # TODO: Compute accuracy on the first 300 training samples which is y_train[:300]\n",
    "    results['acc_train'] = \n",
    "        \n",
    "    # TODO: Compute accuracy on test set using accuracy_score()\n",
    "    results['acc_test'] =\n",
    "    \n",
    "    # TODO: Compute F-score on the the first 300 training samples using fbeta_score()\n",
    "    results['f_train'] = \n",
    "        \n",
    "    # TODO: Compute F-score on the test set which is y_test\n",
    "    results['f_test'] =  \n",
    "       \n",
    "    # Success\n",
    "    print(\"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size))\n",
    "        \n",
    "    # Return the results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente celda, implementa lo siguiente:\n",
    "* Importa los tres modelos de aprendizaje que discutiste en la anterior sección\n",
    "* Inicializalos como clf_A, clf_B y clf_C.\n",
    "* Asigna el parámetro random_state con el mismo valor para los modelos que lo permitan\n",
    "* No asignes parámetros a tus modelos excepto el anterior. Luego ajustaremos un modelo específico.\n",
    "* Calcula el número de registros igual a 1%, 10% y 100% del training set.\n",
    "\n",
    "Se puede tomar un tiempo en entrenar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import the three supervised learning models from sklearn\n",
    "\n",
    "# TODO: Initialize the three models\n",
    "clf_A = # TODO\n",
    "clf_B = # TODO\n",
    "clf_C = # TODO\n",
    "\n",
    "# TODO: Calculate the number of samples for 1%, 10%, and 100% of the training data\n",
    "# HINT: samples_100 is the entire training set i.e. len(y_train)\n",
    "# HINT: samples_10 is 10% of samples_100 (ensure to set the count of the values to be `int` and not `float`)\n",
    "# HINT: samples_1 is 1% of samples_100 (ensure to set the count of the values to be `int` and not `float`)\n",
    "samples_100 = # TODO\n",
    "samples_10 = # TODO\n",
    "samples_1 = # TODO\n",
    "\n",
    "# Collect results on the learners\n",
    "results = {}\n",
    "for clf in [clf_A, clf_B, clf_C]:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    results[clf_name] = {}\n",
    "    for i, samples in enumerate([samples_1, samples_10, samples_100]):\n",
    "        results[clf_name][i] = \\\n",
    "        train_predict(clf, samples, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Run metrics visualization for the three supervised learning models chosen\n",
    "vs.evaluate(results, accuracy, fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mejorando resultados\n",
    "\n",
    "En esta última sección, elegirás el mejor modelo. Después de esto, utilizarás la técnica de grid search con todo el training set para ajustar por lo menos un parámetro con el objetivo de mejorar el F-score\n",
    "\n",
    "## Pregunta 3\n",
    "\n",
    "Revisa las gráficas anteriores. Describe en un párrafo el comportamiento de cada modelo y sus ventajas. ¿Cuál es el modelo que consideras más apropiado? En tu discusión, menciona:\n",
    "* Métricas - F score en el testing cuando se usa el 100% del training set\n",
    "* Tiempo de entrenamiento\n",
    "* Qué tan bueno es el algoritmo para tu información\n",
    "\n",
    "**Respuesta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 4\n",
    "\n",
    "En uno o dos párafos explica de qué manera funciona el modelo que elegiste. Asegúrate de describir las mejores cualidades del modelo, por ejemplo, la manera en la que se entrena o de qué manera hace predicciones. Evita utilizar fórmulas o explicaciones complejas.\n",
    "\n",
    "**Respuesta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning\n",
    "\n",
    "Es hora de ajustar los parámetros del modelo que elegiste. Utiliza grid search (`GridSearchCV`) con un parámetro mínimo con 3 valores diferentes. Utiliza todo el training set para este paso. En la siguiente celda, implementa:\n",
    "\n",
    "* Importa `sklearn.grid_search.GridSearchCV` y `sklearn.metrics.make_scorer`\n",
    "* Inicia el clasificador que elegiste en clf\n",
    "* Elige el mismo random_state que antes\n",
    "* crea un diccionario con los parámetros que quieres ajustar.\n",
    "Ejemplo: `parameters = {'parameter' : [list of values]}`.\n",
    "* Evita utilizar el parámetro max_features\n",
    "* Utiliza `make_scorer` para crear un objeto que califique con `fbeta_score` con un $\\beta = 0.5$.\n",
    "* Aplica grid search en el clasificador `clf` utiizando el `scorer`, y guarda el resultado en `grid_obj`\n",
    "* Haz un fit con X_train y y_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import 'GridSearchCV', 'make_scorer', and any other necessary libraries\n",
    "\n",
    "# TODO: Initialize the classifier\n",
    "clf = \n",
    "\n",
    "# TODO: Create the parameters list you wish to tune, using a dictionary if needed.\n",
    "# HINT: parameters = {'parameter_1': [value1, value2], 'parameter_2': [value1, value2]}\n",
    "parameters = \n",
    "\n",
    "# TODO: Make an fbeta_score scoring object using make_scorer()\n",
    "scorer = \n",
    "\n",
    "# TODO: Perform grid search on the classifier using 'scorer' as the scoring method using GridSearchCV()\n",
    "grid_obj = \n",
    "\n",
    "# TODO: Fit the grid search object to the training data and find the optimal parameters using fit()\n",
    "grid_fit = \n",
    "\n",
    "# Get the estimator\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "# Make predictions using the unoptimized and model\n",
    "predictions = (clf.fit(X_train, y_train)).predict(X_test)\n",
    "best_predictions = best_clf.predict(X_test)\n",
    "\n",
    "# Report the before-and-afterscores\n",
    "print(\"Unoptimized model\\n------\")\n",
    "print(\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test, predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, predictions, beta = 0.5)))\n",
    "print(\"\\nOptimized Model\\n------\")\n",
    "print(\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n",
    "print(\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 5 - Evaluación Final\n",
    "* ¿Cuál fue el F-score y el accuracy de tu modelo con testing data? ¿Son mejores o peores que el modelo no optimizado?\n",
    "* ¿Cómo se compara el modelo optimizado con el predictor ingenuo de la primera pregunta?\n",
    "\n",
    "**Respuesta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importancia de Features\n",
    "\n",
    "Una tarea importante al manejar un dataset es determinar qué features tienen más poder predictivo. Al enfocarnos en la relación entre unos pocos features cruciales y el label objetivo, simplificamos lo que entendemos del fenómeno. Para este proyecto, significa que queremos identificar pocos features que importen mucho para identificar si un individuo hace más de \\$50, 000.\n",
    "\n",
    "Utilizaremos random forest, un clasificador que tiene un parámetro `feature_importance_attribute`, el cuál es una función que hace un ranking de la importancia de los features.\n",
    "\n",
    "### Pregunta 6\n",
    "Cuando exploramos la data, vimos que tenemos 13 features disponibles para cada entrada. De esos 13 features, ¿cuáles \n",
    "crees que sean los 5 más importantes para hacer una predicción? ¿En qué orden los rankearías?\n",
    "\n",
    "**Respuesta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente celda implementaremos:\n",
    "* Importaremos RandomForest \n",
    "* Lo entrenaremos con todo el training set\n",
    "* Extraeremos la importancia de los features con `.feature_importances_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# TODO: Train the supervised model on the training set \n",
    "model = \n",
    "\n",
    "# TODO: Extract the feature importances\n",
    "importances =\n",
    "\n",
    "# Plot\n",
    "vs.feature_plot(importances, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 7\n",
    "\n",
    "Observa la visualización. Esta despliega los 5 features más relevantes para esta tarea con un RandomForest.\n",
    "* ¿De qué manera se comparan estos 5 features con los que propusiste en la sexta pregunta?\n",
    "* ¿La visualización confirma tu hipótesis?\n",
    "* ¿Por qué crees que estos features son más relevantes? (si es que son diferentes)\n",
    "\n",
    "**Respuesta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de features\n",
    "\n",
    "¿Cómo se desempeña un modelo si sólo utilizamos los features importantes? Con menos features requeridos, esperaríamos que el modelo se entrenaría mucho más rápido. En la visualización se ve que los 5 features más importantes contribuyen más de la mitad a la importancia. Esto es una prueba que podemos reducir el espacio de features sin reducir nuestras métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functionality for cloning a model\n",
    "from sklearn.base import clone\n",
    "\n",
    "# Reduce the feature space\n",
    "X_train_reduced = X_train[X_train.columns.values[(np.argsort(importances)[::-1])[:5]]]\n",
    "X_test_reduced = X_test[X_test.columns.values[(np.argsort(importances)[::-1])[:5]]]\n",
    "\n",
    "# Train on the \"best\" model found from grid search earlier\n",
    "clf = (clone(best_clf)).fit(X_train_reduced, y_train)\n",
    "\n",
    "# Make new predictions\n",
    "reduced_predictions = clf.predict(X_test_reduced)\n",
    "\n",
    "# Report scores from the final model using both versions of data\n",
    "print(\"Final Model trained on full data\\n------\")\n",
    "print(\"Accuracy on testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5)))\n",
    "print(\"\\nFinal Model trained on reduced data\\n------\")\n",
    "print(\"Accuracy on testing data: {:.4f}\".format(accuracy_score(y_test, reduced_predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, reduced_predictions, beta = 0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 8\n",
    "¿Cómo se compara el F-score y accuracy entre el modelo entrenado con menos features y el original? ¿Si el tiempo de entrenamiento fuera un factor, considerarías reducir la la cantidad de información?\n",
    "\n",
    "**Respuesta**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

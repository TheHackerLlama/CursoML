{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas de Evaluación e Introducción a Scikit Learn\n",
    "Hasta el momento, hemos implementado los algoritmos directamente. En la vida real, implementar los algoritmos desde cero no es la mejor idea. Scikit Learn es una librería de computación científica con clases que ya implementan algoritmos de aprendizaje como regresión lineal, logística, árboles de decisiones y Support Vector Machines (SVM).\n",
    "\n",
    "En este cuaderno aprenderemos un poco de las herramientas que tenemos y aprenderemos a comparar diferentes algoritmos en el mismo problema.\n",
    "\n",
    "Antes de comenzar, recuerda instalar scikit-learn desde tu ambiente con ```conda install scikit-learn```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets # sklearn ya tiene varios datasets cargados\n",
    "from sklearn import metrics # también tiene métricas para evaluar un modelo\n",
    "from sklearn.linear_model import LinearRegression # Y ya tiene regresión lineal implementada!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta función grafica un clasificador\n",
    "def plot_model(X, y, clf):\n",
    "    plt.scatter(X[np.argwhere(y==0).flatten(),0],X[np.argwhere(y==0).flatten(),1],s = 50, color = 'blue', edgecolor = 'k')\n",
    "    plt.scatter(X[np.argwhere(y==1).flatten(),0],X[np.argwhere(y==1).flatten(),1],s = 50, color = 'red', edgecolor = 'k')\n",
    "\n",
    "    plt.xlim(-2.05,2.05)\n",
    "    plt.ylim(-2.05,2.05)\n",
    "    plt.grid(False)\n",
    "    plt.tick_params(\n",
    "        axis='x',\n",
    "        which='both',\n",
    "        bottom='off',\n",
    "        top='off')\n",
    "\n",
    "    r = np.linspace(-2.1,2.1,300)\n",
    "    s,t = np.meshgrid(r,r)\n",
    "    s = np.reshape(s,(np.size(s),1))\n",
    "    t = np.reshape(t,(np.size(t),1))\n",
    "    h = np.concatenate((s,t),1)\n",
    "\n",
    "    z = clf.predict(h)\n",
    "\n",
    "    s = s.reshape((np.size(r),np.size(r)))\n",
    "    t = t.reshape((np.size(r),np.size(r)))\n",
    "    z = z.reshape((np.size(r),np.size(r)))\n",
    "\n",
    "    plt.contourf(s,t,z,colors = ['blue','red'],alpha = 0.2,levels = range(-1,2))\n",
    "    if len(np.unique(z)) > 1:\n",
    "        plt.contour(s,t,z,colors = 'k', linewidths = 2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Lineal con muchas variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos un dataset público de los precios de las casas de boston\n",
    "housing_data = datasets.load_boston()\n",
    "print(\"Features: \" , housing_data.feature_names)\n",
    "print(\"Ejemplo de un input: \", housing_data.data[0])\n",
    "print(\"Ejemplo de un output: \" , housing_data.target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el modelo (no entrenado)\n",
    "linear_regression_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos un fit de la línea dado sus valores en x y en y.\n",
    "linear_regression_model.fit(housing_data.data, housing_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos predicciones de nuestro data. Nota que aquí estamos usando lo mismo con lo que entrenamos! (mala práctica)\n",
    "predictions = linear_regression_model.predict(housing_data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos\n",
    "error = metrics.mean_absolute_error(housing_data.target, predictions)\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos\n",
    "error = metrics.mean_squared_error(housing_data.target, predictions)\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = metrics.r2_score(housing_data.target, predictions)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación de Clasificación\n",
    "Ahora veremos 3 diferentes técnicas para clasificar y evaluaremos cuál funciona mejor en varios datasets.\n",
    "\n",
    "### Problema 1.\n",
    "Iniciamos cargando la información usando pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.read_csv(\"data/small_test.csv\")\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente celda graficamos por categoría. La respuesta de cómo hacer esto está en stackoverflow:\n",
    "https://stackoverflow.com/questions/21654635/scatter-plots-in-pandas-pyplot-how-to-plot-by-category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class(data):\n",
    "    groups = data.groupby('y')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.margins(0.05) # Optional, just adds 5% padding to the autoscaling\n",
    "    for name, group in groups:\n",
    "        ax.plot(group.x1, group.x2, marker='o', linestyle='', ms=12, label=name)\n",
    "    ax.legend()\n",
    "\n",
    "    plt.show()\n",
    "plot_class(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos features de label\n",
    "X = np.array(data[['x1', 'x2']])\n",
    "y = np.array(data['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de input\n",
    "X[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente celda implementamos regresión logística. Son 5 pasos:\n",
    "1. Cargamos el modelo de la librería donde está\n",
    "2. Creamos una instancia de la técnica (LogisticRegression())\n",
    "3. Hacemos un fit de X y y.\n",
    "4. Predecimos con el clasificador para X.\n",
    "5. Utilizamos accuracy_score para medir su desempeño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X,y)\n",
    "predictions = classifier.predict(X)\n",
    "metrics.accuracy_score(y, predictions)\n",
    "plot_model(X, y, classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Repite este proceso en las dos siguientes celdas con un árbol de decisión y con un SVC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Pon tu código\n",
    "plot_model(X, y, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "from sklearn.svm import SVC\n",
    "# Pon tu código\n",
    "plot_model(X, y, classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema 2.\n",
    "En el anterior problema, estaba muy claras las separaciones. Ahora trabajaremos con información más compleja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.read_csv(\"data/second_test.csv\")\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(data[['x1', 'x2']])\n",
    "y = np.array(data['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este problema, vamos a utilizar un SVM (SVC). En el anterior ejercicio, no especificamos los parámetros del modelo. Ahora, vamos a configurar el SVC y ver cómo funciona mejor. Los valores más comunes son:\n",
    "* kernel (string): linear, poly, rbf\n",
    "* degree (int): grado del polinomio si elegiste poly\n",
    "* gamma (float): Parámetro gama que se usa con kernel rbf.\n",
    "\n",
    "classifier = SVC(kernel = ..., degree = ..., gamma = ...)\n",
    "\n",
    "Prueba con linear primero, y luego prueba con otro. ¿Puedes lograr un accuracy de 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SVC(kernel = 'linear')\n",
    "classifier.fit(X,y)\n",
    "predictions = classifier.predict(X)\n",
    "metrics.accuracy_score(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(X, y, classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta** Investiga en la documentación de SVC qué significa cada parámetro (kernel y gamma). ¿Cuál fue tu accuracy con las diferentes combinaciones de parámetros. ¿Por qué uno funcionó mejor que otro?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema 3.\n",
    "El objetivo de este problema es mostrar cómo hacer un split de información con scikit learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.read_csv(\"data/third_test.csv\")\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X = np.array(data[['x1', 'x2']])\n",
    "y = np.array(data['y'])\n",
    "\n",
    "# Usamos train_test_split para separar el 20% a testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2) \n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SVC(kernel = 'rbf', gamma = 5)\n",
    "\n",
    "# Entrenamos con training data\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluamos con testing data\n",
    "predictions = classifier.predict(X_test)\n",
    "metrics.accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(X, y, classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos hacer K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "X = np.array(data[['x1', 'x2']])\n",
    "y = np.array(data['y'])\n",
    "kf = KFold(n_splits=2)\n",
    "kf.get_n_splits(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema 4. \n",
    "Ahora veremos cómo aplicar Grid Search. Recuerda, a veces hay muchos parámetros para los modelos y Grid Search permite explorar eso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos datos\n",
    "data = pandas.read_csv(\"data/problem4.csv\")\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(data[['x1', 'x2']])\n",
    "y = np.array(data['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos train_test_split para separar el 20% a testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2) \n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el clasificador\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predecimos\n",
    "train_predictions = classifier.predict(X_train)\n",
    "test_predictions = classifier.predict(X_test)\n",
    "\n",
    "plot_model(X, y, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos F1\n",
    "from sklearn.metrics import f1_score\n",
    "print('The Training F1 Score is', f1_score(train_predictions, y_train))\n",
    "print('The Testing F1 Score is', f1_score(test_predictions, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un F1 de 1 en el entrenamiento es una clara muestra de overfitting! Veamos cómo usar GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Creamos un clasificador\n",
    "classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Hacemos lista de los parámetros que queremos probar\n",
    "parameters = {'max_depth':[2,4,6,8,10],'min_samples_leaf':[2,4,6,8,10], 'min_samples_split':[2,4,6,8,10]}\n",
    "\n",
    "# Hacemos un scorer para que evalue\n",
    "scorer = make_scorer(f1_score)\n",
    "\n",
    "# Creamos el Grid Object. \n",
    "grid_obj = GridSearchCV(classifier, parameters, scoring=scorer)\n",
    "\n",
    "# Entrenamos\n",
    "grid_fit = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Conseguimos el mejor estimador\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "# Ahora lo entrenamos en entrenamiento\n",
    "best_clf.fit(X_train, y_train)\n",
    "\n",
    "# Hacemos predicciones\n",
    "best_train_predictions = best_clf.predict(X_train)\n",
    "best_test_predictions = best_clf.predict(X_test)\n",
    "\n",
    "# Calculamos f1\n",
    "print('The training F1 Score is', f1_score(best_train_predictions, y_train))\n",
    "print('The testing F1 Score is', f1_score(best_test_predictions, y_test))\n",
    "\n",
    "# Graficamos\n",
    "plot_model(X, y, best_clf)\n",
    "\n",
    "# Veamos los parámetros del mejor modelo\n",
    "best_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un scorer\n",
    "scorer = make_scorer(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Seleccionamos parámetros\n",
    "parameters = {'kernel':['poly', 'rbf'],'C':[0.1, 1, 10]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema 5. \n",
    "En este problema, haz los siguientes pasos\n",
    "\n",
    "1. Grafica\n",
    "2. Carga la información de x y la información de y\n",
    "3. Separa en training y testing.\n",
    "4. Crea un clasificador SVC, pero no lo entrenes.\n",
    "5. Utiliza GridSearch para encontrar el mejor model.\n",
    "6. Con el mejor modelo, vuelve a entrenarlo con el training. \n",
    "7. Calcula el F1. Revisa http://scikit-learn.org/stable/modules/classes.html#classification-metrics y elige otras dos maneras de calcular el score. \n",
    "8. Grafica el clasificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.read_csv(\"data/small_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
